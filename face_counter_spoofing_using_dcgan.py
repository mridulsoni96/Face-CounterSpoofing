# -*- coding: utf-8 -*-
"""kj832715_Face_Counter_spoofing_using_DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HG18HtGYipWEdYDNk2B1pC2MK8b7NY1G

**Loading** **Libraries**
"""

#%matplotlib inline
import argparse
import os
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML
import pandas as pd
from PIL import Image
import seaborn as sns
from sklearn.metrics import accuracy_score, roc_curve, auc


# Set random seed for reproducibility
manualSeed = 777
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)
torch.use_deterministic_algorithms(True) # Needed for reproducible results

"""**Connecting to the Drive**"""

from google.colab import drive
drive.mount('/content/drive')
os.chdir('/content/drive/My Drive/Training')

"""**Defining parameters**"""

# Root directory for dataset
dataroot = "/content/drive/My Drive/Training"

# Number of workers for dataloader
workers = 2

# Batch size during training
batch_size = 128

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size = 64

# Number of channels in the training images. For color images this is 3
nc = 3

# Size of z latent vector (i.e. size of generator input)
nz = 100

# Size of feature maps in generator
ngf = 64

# Size of feature maps in discriminator
ndf = 64

# Number of training epochs
num_epochs = 351

# Learning rate for optimizers
lr = 0.0002

# Beta1 hyperparameter for Adam optimizers
beta1 = 0.5

# Number of GPUs available. Use 0 for CPU mode.
ngpu = 1

"""**Displaying Training Images**"""

# We can use an image folder dataset the way we have it setup
# Create the dataset
dataset = dset.ImageFolder(dataroot,
                           transform=transforms.Compose([
                               transforms.Resize(image_size),
                               transforms.CenterCrop(image_size),
                               transforms.ToTensor(),
                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
                           ]),
is_valid_file=lambda x: x.endswith(('.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'))
                           )
# Create the dataloader
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=workers)

# Decide which device we want to run on
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

# Plot some training images
real_batch = next(iter(dataloader))
plt.figure(figsize=(8,8))
plt.axis("off")

plt.title("Training Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))

"""**Initialising Weights**"""

# custom weights initialization called on ``netG`` and ``netD``
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

"""**Generator Code**"""

# Generator Code

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. ``(ngf*8) x 4 x 4``
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. ``(ngf*4) x 8 x 8``
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. ``(ngf*2) x 16 x 16``
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. ``(ngf) x 32 x 32``
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. ``(nc) x 64 x 64``
        )

    def forward(self, input):
        return self.main(input)

# Create the generator
netG = Generator(ngpu).to(device)

# Handle multi-GPU if desired
if (device.type == 'cuda') and (ngpu > 1):
    netG = nn.DataParallel(netG, list(range(ngpu)))

# Apply the ``weights_init`` function to randomly initialize all weights
#  to ``mean=0``, ``stdev=0.02``.
netG.apply(weights_init)

# Print the model
print(netG)

"""**Discriminator Code**"""

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is ``(nc) x 64 x 64``
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. ``(ndf) x 32 x 32``
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. ``(ndf*2) x 16 x 16``
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. ``(ndf*4) x 8 x 8``
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. ``(ndf*8) x 4 x 4``
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

# Create the Discriminator
netD = Discriminator(ngpu).to(device)

# Handle multi-GPU if desired
if (device.type == 'cuda') and (ngpu > 1):
    netD = nn.DataParallel(netD, list(range(ngpu)))

# Apply the ``weights_init`` function to randomly initialize all weights
# like this: ``to mean=0, stdev=0.2``.
netD.apply(weights_init)

# Print the model
print(netD)

"""**Defining Variables**"""

# Initialize the ``BCELoss`` function
criterion = nn.BCELoss()

# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
fixed_noise = torch.randn(64, nz, 1, 1, device=device)

# Establish convention for real and fake labels during training
real_label = 1.
fake_label = 0.

# Setup Adam optimizers for both G and D
optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))

val_interval = 5  # Perform validation every `val_interval` epochs
val_accuracies = []  # List to store validation accuracies

val_interval_epochs = 50

epochs_to_run = [350]

# Initialize lists to store genuine and attack scores for each epoch
genuine_scores_list = []
attack_scores_list = []

# Initialize lists to store APCER and BPCER values for various thresholds
thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]  # Specify the thresholds you want to evaluate
apcer_values = [[] for _ in thresholds]
bpcer_values = [[] for _ in thresholds]

# Specify the directory path to save results
save_dir_plots = "/content/drive/My Drive/Generated/plots"
save_dir_models = "/content/drive/My Drive/Generated/models"
save_dir_images = "/content/drive/My Drive/Generated/images"

"""**Training and Validation Loop**"""

# Commented out IPython magic to ensure Python compatibility.
# Training Loop

# Lists to keep track of progress
img_list = []
G_losses = []
D_losses = []
iters = 0

print("Starting Training Loop...")

# Import necessary libraries
from sklearn.model_selection import KFold

# Define the number of folds for cross-validation
num_folds = 7

# Create a KFold cross-validator
kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)

# Lists to keep track of progress
genuine_scores_list = []
attack_scores_list = []

# Perform k-fold cross-validation
for fold, (train_indices, val_indices) in enumerate(kfold.split(dataset)):
    print("--------------------------------------------------------------------------------------------------")
    print(f"Starting Fold {fold + 1}...")
    print("--------------------------------------------------------------------------------------------------")

    # Split dataset into training and validation sets for this fold
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)

    # Create dataloaders for training and validation sets
    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)
    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)


    # For each epoch
    for epoch in range(num_epochs):
          # For each batch in the dataloader
            for i, data in enumerate(train_dataloader, 0):

                ############################
                # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
                ###########################
                ## Train with all-real batch
                netD.zero_grad()
                # Format batch
                real_cpu = data[0].to(device)
                b_size = real_cpu.size(0)
                label = torch.full((b_size,), real_label, dtype=torch.float, device=device)
                # Forward pass real batch through D
                output = netD(real_cpu).view(-1)
                # Calculate loss on all-real batch
                errD_real = criterion(output, label)
                # Calculate gradients for D in backward pass
                errD_real.backward()
                D_x = output.mean().item()

                ## Train with all-fake batch
                # Generate batch of latent vectors
                noise = torch.randn(b_size, nz, 1, 1, device=device)
                # Generate fake image batch with G
                fake = netG(noise)
                label.fill_(fake_label)
                # Classify all fake batch with D
                output = netD(fake.detach()).view(-1)
                # Calculate D's loss on the all-fake batch
                errD_fake = criterion(output, label)
                # Calculate the gradients for this batch, accumulated (summed) with previous gradients
                errD_fake.backward()
                D_G_z1 = output.mean().item()
                # Compute error of D as sum over the fake and the real batches
                errD = errD_real + errD_fake
                # Update D
                optimizerD.step()

                ############################
                # (2) Update G network: maximize log(D(G(z)))
                ###########################
                netG.zero_grad()
                label.fill_(real_label)  # fake labels are real for generator cost
                # Since we just updated D, perform another forward pass of all-fake batch through D
                output = netD(fake).view(-1)
                # Calculate G's loss based on this output
                errG = criterion(output, label)
                # Calculate gradients for G
                errG.backward()
                D_G_z2 = output.mean().item()
                # Update G
                optimizerG.step()

                # Output training stats
                if i % 50 == 0:
                    print('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f'
#                           % (epoch, num_epochs, i, len(train_dataloader),
                            errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))

                # Save Losses for plotting later
                G_losses.append(errG.item())
                D_losses.append(errD.item())

                # Check how the generator is doing by saving G's output on fixed_noise
                if (iters % 200 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):
                    with torch.no_grad():
                        fake = netG(fixed_noise).detach().cpu()
                    img_list.append(vutils.make_grid(fake, padding=2, normalize=True))

                iters += 1


                # Validation loop
            if epoch % val_interval == 0:  # Perform validation at specific intervals
                netD.eval()  # Set discriminator to evaluation mode
                val_loss = 0.0
                val_correct = 0
                total_samples = 0
                val_genuine_scores = []
                val_attack_scores = []
                with torch.no_grad():
                    for j, val_data in enumerate(val_dataloader, 0):
                            # Move data to the appropriate device
                        val_real_cpu = val_data[0].to(device)
                        val_b_size = val_real_cpu.size(0)
                        val_label = torch.full((val_b_size,), real_label, dtype=torch.float, device=device)

                            # Forward pass real batch through D
                        val_output = netD(val_real_cpu).view(-1)
                            # Calculate loss on all-real batch
                        val_errD_real = criterion(val_output, val_label)
                        val_D_x = val_output.mean().item()

                            # Generate batch of latent vectors
                        val_noise = torch.randn(val_b_size, nz, 1, 1, device=device)
                            # Generate fake image batch with G
                        val_fake = netG(val_noise)
                        val_label.fill_(fake_label)
                            # Classify all fake batch with D
                        val_output = netD(val_fake.detach()).view(-1)
                            # Calculate D's loss on the all-fake batch
                        val_errD_fake = criterion(val_output, val_label)

                        val_loss += (val_errD_real + val_errD_fake).item()
                        val_correct += torch.sum((val_output > 0.5).float() == val_label).item()
                        total_samples += val_b_size


                        val_genuine_scores.extend(val_output[val_label == real_label].tolist())
                        val_attack_scores.extend(val_output[val_label == fake_label].tolist())


                # Append scores for the current epoch to the lists
                genuine_scores_list.append(val_genuine_scores)
                attack_scores_list.append(val_attack_scores)

                    # Calculate and print validation metrics
                val_loss /= (j + 1)
                val_accuracy = val_correct / total_samples
                val_accuracies.append(val_accuracy)
                print('Validation - Epoch [%d/%d]\tLoss_D: %.4f\tD(x): %.2f%%\tAccuracy: %.2f%%'
#                           % (epoch, num_epochs, val_loss, val_D_x, val_accuracy * 100))

            # Store and plot validation accuracies every val_interval epochs
            if epoch % val_interval_epochs == 0:
                plt.figure(figsize=(10, 6))
                plt.plot(range(0, len(val_accuracies) * val_interval, val_interval), val_accuracies, marker='o')
                plt.xlabel('Iteration')
                plt.ylabel('Validation Accuracy')
                plt.title(f'Validation Accuracy vs. Iteration (Epochs: {num_epochs})')
                plt.grid()
                plot_path = os.path.join(save_dir_plots, f'Validation_accuracy_plot_epochs_{num_epochs}_interval{val_interval_epochs}.png')
                plt.savefig(plot_path)
                plt.close()

            # Save results for the current epoch
            if epoch in epochs_to_run:
                # Save model checkpoints for this fold
                discriminator_checkpoint_path = os.path.join(save_dir_models, f'Discriminator_F{fold + 1}E{epoch}.pth')
                generator_checkpoint_path = os.path.join(save_dir_models, f'Generator_F{fold + 1}E{epoch}.pth')
                torch.save(netD.state_dict(), discriminator_checkpoint_path)
                torch.save(netG.state_dict(), generator_checkpoint_path)
                print("--------------------------------------------------------------------------------------------------")
                print(f"Generator and Discriminator Model saved for Fold:{fold + 1} and Epoch:{epoch}")
                print("--------------------------------------------------------------------------------------------------")

                # Generate and save a fixed number of images using the generator for this fold
                num_images_to_save = 20
                generated_images_path = os.path.join(save_dir_images, f'Generated_Images_F{fold + 1}E{epoch}.png')
                with torch.no_grad():
                    fake_images = netG(fixed_noise[:num_images_to_save]).detach().cpu()
                vutils.save_image(fake_images, generated_images_path, normalize=True, nrow=5)

"""**Accumulated Validation Accuracies Plot**"""

# Plot accumulated validation accuracies after all specified training runs
plt.figure(figsize=(18, 6))
plt.plot(range(0, len(val_accuracies) * val_interval, val_interval), val_accuracies, marker='o')
plt.xlabel('Iteration')
plt.ylabel('Validation Accuracy')
plt.title('Validation Accuracy vs. Iteration (All Epochs)')
plt.grid()
plot_path = os.path.join(save_dir_plots, f'accumulated_validation_accuracy_plot_{num_epochs}.png')
plt.savefig(plot_path)
plt.show()

"""**Mean Accuracies Plot**"""

# Calculate mean accuracies for every 20 epochs
mean_accuracies = [sum(val_accuracies[i:i+20]) / 20 for i in range(0, len(val_accuracies) - 20, 20)]

# Plot mean validation accuracies after all specified training runs
plt.figure(figsize=(18, 6))
plt.plot(range(0, len(mean_accuracies) * 20 * val_interval, 20 * val_interval), mean_accuracies, marker='o')
plt.xlabel('Iteration')
plt.ylabel('Mean Validation Accuracy')
plt.title('Mean Validation Accuracy vs. Iteration (All Epochs)')
plt.grid()
plot_path = os.path.join(save_dir_plots, f'mean_validation_accuracy_plot_{num_epochs}.png')
plt.savefig(plot_path)
plt.show()

"""**Generator and Discriminator Loss During Training Plot**"""

plt.figure(figsize=(18,6))
plt.title("Generator and Discriminator Loss During Training")
plt.plot(G_losses,label="Generator")
plt.plot(D_losses,label="Discriminator")
plt.xlabel("Iterations")
plt.ylabel("Loss")
plt.legend()

plot_path = os.path.join(save_dir_plots, f'Generator_and_Discriminator_Loss_During_Training_{num_epochs}.png')
plt.savefig(plot_path)
plt.show()

"""**Calculate APCER for various thresholds**"""

# Calculate APCER and BPCER for various thresholds
for epoch in range(len(genuine_scores_list)):
    genuine_scores = genuine_scores_list[epoch]
    attack_scores = attack_scores_list[epoch]

    for i, threshold in enumerate(thresholds):
        apcer = sum(score >= threshold for score in attack_scores) / len(attack_scores)

        if len(genuine_scores) > 0:
            bpcer = sum(score < threshold for score in genuine_scores) / len(genuine_scores)
        else:
            bpcer = 1.0  # high error rate when genuine_scores is empty

        apcer_values[i].append(apcer)

        # Append the same number of values to bpcer_values as in apcer_values
        bpcer_values[i].append(bpcer)  # Append bpcer value

# Plotting code for APCER over epochs and various thresholds

thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]

for i, threshold in enumerate(thresholds):
    plt.figure(figsize=(20, 6))
    plt.plot(range(497), apcer_values[i], label=f'APCER (Threshold {threshold})')
    plt.xlabel('Epoch')
    plt.ylabel('Error Rate')
    plt.title('APCER vs Epoch')
    plt.legend()
    plt.ylim(0, 1)
    plot_path = os.path.join(save_dir_plots, f'apcer_plot_threshold_{threshold}_{num_epochs}.png')
    plt.savefig(plot_path)
    plt.show()

"""**Animation**"""

import matplotlib.animation as animation

#Code to create the animation
fig = plt.figure(figsize=(8, 8))
plt.axis("off")
ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)

# Define the directory and animation filename
save_dir_animation = "/content/drive/My Drive/Generated/animation"
animation_filename = f"animation{num_epochs}.mp4"

# Create the full path to save the animation
full_animation_path = os.path.join(save_dir_animation, animation_filename)

# Save the animation as a video file
ani.save(full_animation_path, writer='ffmpeg', dpi=300)

# Grab a batch of real images from the dataloader
real_batch = next(iter(dataloader))

# Plot the real images
plt.figure(figsize=(15,15))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))

# Plot the fake images from the last epoch
plt.subplot(1,2,2)
plt.axis("off")
plt.title("Fake Images")
plt.imshow(np.transpose(img_list[-1],(1,2,0)))
plt.show()

"""**Loading the final Generator Model**"""

# Load the saved generator model
generator_checkpoint_path = '/content/drive/My Drive/Generated/models/Generator_F5E400.pth'
loaded_generator = Generator(ngpu).to(device)
loaded_generator.load_state_dict(torch.load(generator_checkpoint_path, map_location=device))
loaded_generator.eval()  # Set the generator to evaluation mode

"""**Generating the images from the Generator**"""

# Generate and save new images using the loaded generator
num_images_to_generate = 20
for i in range(num_images_to_generate):
    with torch.no_grad():
        generated_image = loaded_generator(fixed_noise[i:i+1]).detach().cpu()[0]
    generated_image_path = os.path.join(save_dir_images, f'generated_image_{i}.png')
    vutils.save_image(generated_image, generated_image_path, normalize=True)

"""**Models Accuracy**"""

# Define the image transformations
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# Function to classify an image based on a given threshold
def classify_image(image_path, discriminator_model, threshold):
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0).to(device)

    # Forward pass through the discriminator model
    with torch.no_grad():
        output = discriminator_model(image_tensor)

    # Classify based on the threshold
    classification = 1 if output.item() >= threshold else 0

    return classification


def test_models_on_dataset(models, folder_path, thresholds):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    ngpu = 1  # Set this to the number of GPUs used during training (same as before)
    accuracies = []

    for model_checkpoint in models:
        discriminator = Discriminator(ngpu).to(device)
        loaded_dict = torch.load(model_checkpoint, map_location=device)
        if ngpu > 1:
            discriminator.module.load_state_dict(loaded_dict)
        else:
            discriminator.load_state_dict(loaded_dict)

        model_accuracies = []

        for threshold in thresholds:
            y_true = []  # True labels
            y_pred = []  # Predicted labels

            for filename in os.listdir(folder_path):
                if filename.endswith(".jpg") or filename.endswith(".png"):
                    image_path = os.path.join(folder_path, filename)
                    classification = classify_image(image_path, discriminator, threshold)
                    y_true.append(1) if filename.startswith("bonafide") else y_true.append(0)
                    y_pred.append(classification)

            accuracy = accuracy_score(y_true, y_pred)
            model_accuracies.append(accuracy * 100)

        accuracies.append(model_accuracies)

    return accuracies


def main():
    models = [
        '/content/drive/My Drive/Generated/models/Discriminator_F4E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F5E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F6E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F7E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_E5000.pth',
        # Add more paths as needed
    ]


    folder_path = "/content/drive/My Drive/testing/morphs/fake"
    thresholds = np.linspace(0.1, 0.9, num=9)  # Modify as needed
    accuracy_df = pd.DataFrame()
    accuracies = test_models_on_dataset(models, folder_path, thresholds)

    # Plot and save the line graph
    plt.figure(figsize=(8, 8))
    for i, model_checkpoint in enumerate(models):
        model_name = [
            'Model: F4E400',
            'Model: F5E400',
            'Model: F6E350',
            'Model: F7E350',
            'Model: E5000',
            # Add more names as needed
        ]
        rounded_accuracies = [round(acc, 2) for acc in accuracies[i]]
        accuracy_df[model_name[i]] = rounded_accuracies

    # Print the accuracy DataFrame
    print("Accuracy Values:\n", accuracy_df)

    # Plot and save the line graph
    plt.figure(figsize=(12, 8))
    for i, model_checkpoint in enumerate(models):
        plt.plot(thresholds, accuracies[i], label=f'{model_name[i]}')

    plt.xlabel('Threshold')
    plt.ylabel('Accuracy (in %)')
    plt.title('Model Accuracy vs. Threshold')
    plt.legend()
    plt.grid()
    plt.xlim(0, 1)
    plt.ylim(0, 100)

    # Save the plot
    save_dir_plots = '/content/drive/My Drive/Generated/plots'  # Modify the directory path
    plot_filename = os.path.join(save_dir_plots, f'accuracy_vs_threshold_{num_epochs}.png')
    plt.savefig(plot_filename, dpi=300)  # Set DPI for higher resolution
    plt.show()

if __name__ == "__main__":
    main()

"""**EER, APCER and BPCER**"""

from sklearn.metrics import roc_curve

def calculate_eer(labels, scores, threshold):
    fpr, tpr, _ = roc_curve(labels, scores)
    fnr = 1 - tpr
    eer_idx = np.argmin(np.abs(fnr - fpr))
    eer = (fpr[eer_idx] + fnr[eer_idx]) / 2
    return eer

def load_discriminator(model_checkpoint):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    netD = Discriminator(ngpu).to(device)
    netD.load_state_dict(torch.load(model_checkpoint, map_location=device))
    netD.eval()
    return netD

eer_list_all = []
apcer_list_all = []
bpcer_list_all = []


def calculate_eer_and_apcer(netD, test_image_folder, thresholds):
    scores = []
    labels = []

    for subfolder in os.listdir(test_image_folder):
        subfolder_path = os.path.join(test_image_folder, subfolder)
        if os.path.isdir(subfolder_path):
            is_fake = 1 if subfolder == "fake" else 0
            for image_filename in os.listdir(subfolder_path):
                image_path = os.path.join(subfolder_path, image_filename)
                image = Image.open(image_path).convert('RGB')
                image_tensor = transform(image).unsqueeze(0).to(device)
                output = netD(image_tensor).item()
                scores.append(output)
                labels.append(is_fake)

    eer_list = []
    apcer_list = []
    bpcer_list = []

    for threshold in thresholds:
        eer = calculate_eer(labels, scores, threshold)
        apcer = calculate_apcer(labels, scores, threshold)
        bpcer = calculate_bpcer(labels, scores, threshold)
        eer_list.append(eer)
        apcer_list.append(apcer)
        bpcer_list.append(bpcer)

    return eer_list, apcer_list, bpcer_list
def calculate_apcer(labels, scores, threshold):
    predictions = [1 if score >= threshold else 0 for score in scores]
    attack_indices = [i for i, label in enumerate(labels) if label == 1]
    apcer = np.mean(np.array(predictions)[attack_indices] == 0)
    return apcer

def calculate_bpcer(labels, scores, threshold):
    predictions = [1 if score < threshold else 0 for score in scores]
    genuine_indices = [i for i, label in enumerate(labels) if label == 1]
    bpcer = np.mean(np.array(predictions)[genuine_indices] == 0)
    return bpcer

def plot_eer_apcer_bpcer_heatmap(eer_list, apcer_list, bpcer_list, model_names, thresholds):
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))

    # Plot EER values as heatmap
    sns.heatmap(eer_list, cmap="YlGnBu", annot=True, fmt=".2f", xticklabels=thresholds, yticklabels=model_names, ax=ax1)
    ax1.set_title('EER Values')

    # Plot APCER values as heatmap
    sns.heatmap(apcer_list, cmap="YlGnBu", annot=True, fmt=".2f", xticklabels=thresholds, yticklabels=model_names, ax=ax2)
    ax2.set_title('APCER Values')

    # Plot BPCER values as heatmap
    sns.heatmap(bpcer_list, cmap="YlGnBu", annot=True, fmt=".2f", xticklabels=thresholds, yticklabels=model_names, ax=ax3)
    ax3.set_title('BPCER Values')

    plt.tight_layout()
    plot_path = os.path.join(save_dir_plots, f'APCER_BPCER_EER_heatmap.png')
    plt.savefig(plot_path)
    plt.show()

def main():
    model_checkpoints = [
        '/content/drive/My Drive/Generated/models/Discriminator_F4E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F5E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F6E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F7E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_E5000.pth',
        # Add more paths as needed
    ]

    test_image_folder = '/content/drive/My Drive/testing/morphs/'
    save_dir_plots = '/content/drive/My Drive/Generated/plots'
    thresholds = [0.1, 0.05, 0.01]

    netD_list = [load_discriminator(model_checkpoint) for model_checkpoint in model_checkpoints]
    model_names = [
        'Model: F4E400',
        'Model: F5E400',
        'Model: F6E350',
        'Model: F7E350',
        'Model: E5000',
        # Add more names as needed
        ]


    for netD in netD_list:
        eer_list, apcer_list, bpcer_list = calculate_eer_and_apcer(netD, test_image_folder, thresholds)
        eer_list_all.append(eer_list)
        apcer_list_all.append(apcer_list)
        bpcer_list_all.append(bpcer_list)

    plot_eer_apcer_bpcer_heatmap(eer_list_all, apcer_list_all, bpcer_list_all, model_names, thresholds)

if __name__ == "__main__":
    main()

"""**ROC Curve and DET Curve**"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from PIL import Image
import os
import torch
import torchvision.transforms as transforms


# Function to load the discriminator model
def load_discriminator(model_checkpoint):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    netD = Discriminator(ngpu).to(device)
    netD.load_state_dict(torch.load(model_checkpoint, map_location=device))
    netD.eval()
    return netD

# Function to calculate ROC curve
def calculate_roc_curve(netD, test_image_folder):
    scores = []
    labels = []

    for subfolder in os.listdir(test_image_folder):
        subfolder_path = os.path.join(test_image_folder, subfolder)
        if os.path.isdir(subfolder_path):
            is_fake = 1 if subfolder == "fake" else 0
            for image_filename in os.listdir(subfolder_path):
                image_path = os.path.join(subfolder_path, image_filename)
                image = Image.open(image_path).convert('RGB')
                image_tensor = transform(image).unsqueeze(0).to(device)
                output = netD(image_tensor).item()
                scores.append(output)
                labels.append(is_fake)

    fpr, tpr, _ = roc_curve(labels, scores)
    auc_score = auc(fpr, tpr)

    return fpr, tpr, auc_score

# Function to plot ROC curve
def plot_roc_curve(netD_list, model_checkpoints, test_image_folder, model_names, save_dir_plots):
    plt.figure(figsize=(8, 8))

    for netD, model_checkpoint, model_name in zip(netD_list, model_checkpoints, model_names):
        fpr, tpr, auc_score = calculate_roc_curve(netD, test_image_folder)

        # Plot ROC curve with percentage axes
        fpr_percentage = np.array(fpr) * 100
        tpr_percentage = np.array(tpr) * 100

        # Plot ROC curve
        plt.plot(fpr_percentage, tpr_percentage, label=f'{model_name} (AUC = {auc_score:.2f})')
        plt.xlabel('False Positive Rate (FPR %)')
        plt.ylabel('True Positive Rate (TPR %)')

    plt.xlim([0.0, 100.0])
    plt.ylim([0.0, 100.0])
    plt.title('Receiver Operating Characteristic (ROC) curves')
    plt.legend()
    plt.grid()

    # Save the plot
    plot_filename = os.path.join(save_dir_plots, f'roc_curves_{num_epochs}.png')
    plt.savefig(plot_filename)
    plt.show()

# Function to calculate DET curve
def calculate_det_curve(netD, test_image_folder):
    scores = []
    labels = []

    for subfolder in os.listdir(test_image_folder):
        subfolder_path = os.path.join(test_image_folder, subfolder)
        if os.path.isdir(subfolder_path):
            is_fake = 1 if subfolder == "fake" else 0
            for image_filename in os.listdir(subfolder_path):
                image_path = os.path.join(subfolder_path, image_filename)
                image = Image.open(image_path).convert('RGB')
                image_tensor = transform(image).unsqueeze(0).to(device)
                output = netD(image_tensor).item()
                scores.append(output)
                labels.append(is_fake)

    fpr, tpr, _ = roc_curve(labels, scores)
    fnr = 1 - tpr

    return fpr, fnr

# Function to plot DET curve
def plot_det_curve(netD_list, model_checkpoints, test_image_folder, model_names, save_dir_plots):
    plt.figure(figsize=(8, 8))

    for netD, model_checkpoint, model_name in zip(netD_list, model_checkpoints, model_names):
        fpr, fnr = calculate_det_curve(netD, test_image_folder)

        # Plot DET curve with percentage axes
        fpr_percentage = np.array(fpr) * 100
        fnr_percentage = np.array(fnr) * 100
        plt.plot(fpr_percentage, fnr_percentage, label=f'{model_name}')
        plt.xlabel('False Positive Rate (FPR %)')
        plt.ylabel('False Negative Rate (FNR %)')

    plt.xlim([0.0, 100.0])
    plt.ylim([0.0, 100.0])
    plt.title(f'Detection Error Tradeoff (DET) curves')
    plt.grid(linestyle='--')
    plt.legend()

    # Save the plot
    plot_filename = os.path.join(save_dir_plots, f'det_curves_{num_epochs}.png')
    plt.savefig(plot_filename)
    plt.show()

# Modify your main function
def main():
    model_checkpoints = [
        '/content/drive/My Drive/Generated/models/Discriminator_F4E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F5E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F6E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F7E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_E5000.pth',
        # Add more paths as needed
    ]

    test_image_folder = '/content/drive/My Drive/testing/morphs'

    save_dir_plots = '/content/drive/My Drive/Generated/plots'

    model_names = [
        'Model: F4E400',
        'Model: F5E400',
        'Model: F6E350',
        'Model: F7E350',
        'Model: E5000',
        # Add more names as needed
    ]

    netD_list = [load_discriminator(model_checkpoint) for model_checkpoint in model_checkpoints]

    # Plot ROC curves
    plot_roc_curve(netD_list, model_checkpoints, test_image_folder, model_names, save_dir_plots)

    # Plot DET curves
    plot_det_curve(netD_list, model_checkpoints, test_image_folder, model_names, save_dir_plots)

if __name__ == "__main__":
    main()

"""**Image Classification**"""

import os
from PIL import Image
import torch
import matplotlib.pyplot as plt
import numpy as np

# Function to classify an image as bonafide or fake
def classify_image_label(image_path, discriminator_model, threshold):
    image = Image.open(image_path).convert('RGB')
    image_tensor = transform(image).unsqueeze(0).to(device)

    # Forward pass through the discriminator model
    with torch.no_grad():
        output = discriminator_model(image_tensor)

    # Output is a scalar value between 0 and 1 (0 for fake, 1 for bonafide)
    classification = "bonafide" if output.item() >= threshold else "fake"

    return classification

# Example usage:
def main():
    # Define the path to the folder containing the images
    folder_path = "/content/drive/My Drive/testing/morphs/fake"

    # Define a list of model paths
    model_paths = [
        '/content/drive/My Drive/Generated/models/Discriminator_F4E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F5E400.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F6E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_F7E350.pth',
        '/content/drive/My Drive/Generated/models/Discriminator_E5000.pth',
        # Add more paths as needed
    ]

    custom_model_names = [
        'Model: F4E400',
        'Model: F5E400',
        'Model: F6E350',
        'Model: F7E350',
        'Model: E5000',
        # Add more names as needed
    ]

    # Define a list of thresholds to check
    thresholds = [0.5, 0.7, 0.8, 0.9]

    # Initialize lists to store classification results for each threshold
    all_bonafide_counts = []
    all_fake_counts = []

    # Iterate over each threshold
    for threshold in thresholds:
        # Initialize lists to store classification results for this threshold
        model_names = []
        bonafide_counts = []
        fake_counts = []

        # Load the saved state dictionaries into the models and store them in a list
        loaded_discriminators = []
        for model_path in model_paths:
            loaded_discriminator = Discriminator(ngpu).to(device)
            loaded_dict = torch.load(model_path, map_location=device)
            if ngpu > 1:
                loaded_discriminator.module.load_state_dict(loaded_dict)
            else:
                loaded_discriminator.load_state_dict(loaded_dict)
            loaded_discriminators.append(loaded_discriminator)

        # Iterate over all images in the folder
        for filename in os.listdir(folder_path):
            if filename.endswith((".jpg", ".png")):
                image_path = os.path.join(folder_path, filename)
                print(f"Image: {filename}")

                # Initialize counts for bonafide and fake classifications for each model
                bonafide_counts_per_model = [0] * len(model_paths)
                fake_counts_per_model = [0] * len(model_paths)

                # Classify the image using each discriminator model
                for i, discriminator in enumerate(loaded_discriminators):
                    result = classify_image_label(image_path, discriminator, threshold)
                    model_name = custom_model_names[i]
                    print(f"Model: {model_name}, Classification: {result}")

                    # Count bonafide and fake classifications for the current model
                    if result == "bonafide":
                        bonafide_counts_per_model[i] += 1
                    elif result == "fake":
                        fake_counts_per_model[i] += 1

                # Append counts to the lists
                model_names.append(filename)
                bonafide_counts.append(bonafide_counts_per_model)
                fake_counts.append(fake_counts_per_model)

        # Sum the counts across all images for each model and this threshold
        bonafide_counts_total = np.sum(bonafide_counts, axis=0)
        fake_counts_total = np.sum(fake_counts, axis=0)

        all_bonafide_counts.append(bonafide_counts_total)
        all_fake_counts.append(fake_counts_total)

    # Create separate bar plots for each threshold
    num_models = len(custom_model_names)
    num_thresholds = len(thresholds)

    for i in range(num_thresholds):
        x = np.arange(num_models)
        width = 0.20

        fig, ax = plt.subplots(figsize=(12, 6))
        ax.bar(x - width/2, all_bonafide_counts[i], width, label='Bonafide')
        ax.bar(x + width/2, all_fake_counts[i], width, label='Fake')

        ax.set_ylabel('Counts')
        ax.set_title(f'Bonafide and Fake Counts for Each Model (Threshold={thresholds[i]})')
        ax.set_xticks(x)
        ax.set_xticklabels(custom_model_names)  # Use custom model names as tick labels
        ax.legend()

        plot_filename = os.path.join(save_dir_plots, f'counts_threshold_{thresholds[i]}.png')
        plt.savefig(plot_filename, dpi=300)
        plt.show()

if __name__ == "__main__":
    main()



